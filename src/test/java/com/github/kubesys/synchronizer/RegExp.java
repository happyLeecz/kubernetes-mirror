/**
 * Copyright (2019, ) Institute of Software, Chinese Academy of Sciences
 */
package com.github.kubesys.synchronizer;

/**
 * @author wuheng@otcaix.iscas.ac.cn
 * 
 * @version 2.3.0
 * @since 2020.2.15
 * 
 **/
public class RegExp {
	
	/**
	 * name
	 */
//	public static final String NAME = "\"args\": [\"echo 'dfaaf0dbd2c5111fc0d48475c174933f5753edc6c6b9c2b6df1173d2f6a5d7ef  /src/test.py' \\u003e /tmp/func.sha256 \\u0026\\u0026 sha256sum -c /tmp/func.sha256 \\u0026\\u0026 cp /src/test.py /kubeless/test.py \\u0026\\u0026 cp /src/requirements.txt /kubeless\"],";
	
//	public static final String NAME = "\"cni_network_config\": \"{\\n  \\\"name\\\": \\\"k8s-pod-network\\\",\\n  \\\"cniVersion\\\": \\\"0.3.1\\\"\\n}\"";
	
//	public static final String NAME = "\"prometheus.yml\": \"# my global config\\\\nglobal:\\\\n  scrape_interval:     10s # Set the scrape interval to every 15 seconds. Default is every 1 minute.\\\\n  evaluation_interval: 60s # Evaluate rules every 15 seconds. The default is every 1 minute.\\\\n  scrape_timeout: 10s        # is set to the global default (10s).\\\\n\\\\n# Alertmanager configuration\\\\nalerting:\\\\n  alertmanagers:\\\\n  - static_configs:\\\\n    - targets:\\\\n      # - alertmanager:9093\\\\n\\\\n# Load rules once and periodically evaluate them according to the global \\'evaluation_interval\\'.\\\\nrule_files:\\\\n  # - \\\\\\\"first_rules.yml\\\\\\\"\\\\n  # - \\\\\\\"second_rules.yml\\\\\\\"\\\\n\\\\n# A scrape configuration containing exactly one endpoint to scrape:\\\\n# Here it\\'s Prometheus itself.\\\\nscrape_configs:\\\\n  # The job name is added as a label `job=<job_name\\u003e` to any timeseries scraped from this config.\\\\n  - job_name: \\'prometheus\\'\\\\n\\\\n    # metrics_path defaults to \\'/metrics\\'\\\\n    # scheme defaults to \\'http\\'.\\\\n\\\\n    static_configs:\\\\n      - targets: [\\'localhost:9090\\']\\\\n\\\\n    # metrics_path defaults to \\'/metrics\\'\\\\n    # scheme defaults to \\'http\\'.\\\\n  - job_name: \\'pushgateway\\'\\\\n    static_configs:\\\\n      - targets: [\\'172.17.104.190:9091\\']\\\\n        labels:\\\\n          instance: pushgateway\\\\n\\\\n  - job_name: \\'vms\\'\\\\n\\\\n    # Default to scraping over https. If required, just disable this or change to\\\\n    # `http`.\\\\n    scheme: https\\\\n    metrics_path: /\\\\n\\\\n    # This TLS & bearer token file config is used to connect to the actual scrape\\\\n    # endpoints for cluster components. This is separate to discovery auth\\\\n    # configuration because discovery & scraping are two separate concerns in\\\\n    # Prometheus. The discovery auth config is automatic if Prometheus runs inside\\\\n    # the cluster. Otherwise, more config options have to be provided within the\\\\n    # <kubernetes_sd_config\\u003e.\\\\n    tls_config:\\\\n      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\\\\n    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\\\\n\\\\n    kubernetes_sd_configs:\\\\n    - role: node\\\\n\\\\n    relabel_configs:\\\\n    - action: labelmap\\\\n      regex: __meta_kubernetes_node_label_(.+)\\\\n    - target_label: __address__\\\\n      replacement: kubernetes.default.svc:443\\\\n    - source_labels: [__meta_kubernetes_node_name]\\\\n      regex: (.+)\\\\n      target_label: __metrics_path__\\\\n      replacement: /api/v1/nodes/${1}:19998/proxy/\\\\n  - job_name: \\'node\\'\\\\n\\\\n    # Default to scraping over https. If required, just disable this or change to\\\\n    # `http`.\\\\n    scheme: http\\\\n    #metrics_path: /\\\\n\\\\n    # This TLS & bearer token file config is used to connect to the actual scrape\\\\n    # endpoints for cluster components. This is separate to discovery auth\\\\n    # configuration because discovery & scraping are two separate concerns in\\\\n    # Prometheus. The discovery auth config is automatic if Prometheus runs inside\\\\n    # the cluster. Otherwise, more config options have to be provided within the\\\\n    # <kubernetes_sd_config\\u003e.\\\\n    tls_config:\\\\n      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\\\\n    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\\\\n\\\\n    kubernetes_sd_configs:\\\\n    - role: node\\\\n\\\\n    relabel_configs:\\\\n    - action: labelmap\\\\n      regex: __meta_kubernetes_node_label_(.+)\\\\n    - source_labels: [__meta_kubernetes_node_address_InternalIP]\\\\n      action: replace\\\\n      target_label: __address__\\\\n      regex: (.+)\\\\n      replacement: ${1}:9100\\\\n\\\\n  # - job_name: \\'cadvisor\\'\\\\n\\\\n  #   # Default to scraping over https. If required, just disable this or change to\\\\n  #   # `http`.\\\\n  #   scheme: http\\\\n  #   #metrics_path: /\\\\n  #   tls_config:\\\\n  #     ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\\\\n  #   bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\\\\n\\\\n  #   kubernetes_sd_configs:\\\\n  #   - role: node\\\\n\\\\n  #   relabel_configs:\\\\n  #   - action: labelmap\\\\n  #     regex: __meta_kubernetes_node_label_(.+)\\\\n  #   - source_labels: [__meta_kubernetes_node_address_InternalIP]\\\\n  #     action: replace\\\\n  #     target_label: __address__\\\\n  #     regex: (.+)\\\\n  #     replacement: ${1}:4194\\\\n  #   - source_labels: [__meta_kubernetes_node_name]\\\\n  #     regex: (.+)\\\\n  #     target_label: __metrics_path__\\\\n  #     replacement: /metrics\\\\n\\\\n  - job_name: \\'grafana\\'\\\\n    static_configs:\\\\n      - targets:\\\\n          - \\'grafana-service.kube-system:3000\\'\\\\n\\\\n  - job_name: \\'kubernetes-apiservers\\'\\\\n\\\\n    kubernetes_sd_configs:\\\\n    - role: endpoints\\\\n\\\\n    # Default to scraping over https. If required, just disable this or change to\\\\n    # `http`.\\\\n    scheme: https\\\\n\\\\n    # This TLS & bearer token file config is used to connect to the actual scrape\\\\n    # endpoints for cluster components. This is separate to discovery auth\\\\n    # configuration because discovery & scraping are two separate concerns in\\\\n    # Prometheus. The discovery auth config is automatic if Prometheus runs inside\\\\n    # the cluster. Otherwise, more config options have to be provided within the\\\\n    # <kubernetes_sd_config\\u003e.\\\\n    tls_config:\\\\n      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\\\\n      # If your node certificates are self-signed or use a different CA to the\\\\n      # master CA, then disable certificate verification below. Note that\\\\n      # certificate verification is an integral part of a secure infrastructure\\\\n      # so this should only be disabled in a controlled environment. You can\\\\n      # disable certificate verification by uncommenting the line below.\\\\n      #\\\\n      # insecure_skip_verify: true\\\\n    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\\\\n\\\\n    # Keep only the default/kubernetes service endpoints for the https port. This\\\\n    # will add targets for each API server which Kubernetes adds an endpoint to\\\\n    # the default/kubernetes service.\\\\n    relabel_configs:\\\\n    - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]\\\\n      action: keep\\\\n      regex: default;kubernetes;https\\\\n\\\\n  # Scrape config for nodes (kubelet).\\\\n  #\\\\n  # Rather than connecting directly to the node, the scrape is proxied though the\\\\n  # Kubernetes apiserver.  This means it will work if Prometheus is running out of\\\\n  # cluster, or can\\'t connect to nodes for some other reason (e.g. because of\\\\n  # firewalling).\\\\n  - job_name: \\'kubernetes-nodes\\'\\\\n\\\\n    # Default to scraping over https. If required, just disable this or change to\\\\n    # `http`.\\\\n    scheme: https\\\\n\\\\n    # This TLS & bearer token file config is used to connect to the actual scrape\\\\n    # endpoints for cluster components. This is separate to discovery auth\\\\n    # configuration because discovery & scraping are two separate concerns in\\\\n    # Prometheus. The discovery auth config is automatic if Prometheus runs inside\\\\n    # the cluster. Otherwise, more config options have to be provided within the\\\\n    # <kubernetes_sd_config\\u003e.\\\\n    tls_config:\\\\n      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\\\\n    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\\\\n\\\\n    kubernetes_sd_configs:\\\\n    - role: node\\\\n\\\\n    relabel_configs:\\\\n    - action: labelmap\\\\n      regex: __meta_kubernetes_node_label_(.+)\\\\n    - target_label: __address__\\\\n      replacement: kubernetes.default.svc:443\\\\n    - source_labels: [__meta_kubernetes_node_name]\\\\n      regex: (.+)\\\\n      target_label: __metrics_path__\\\\n      replacement: /api/v1/nodes/${1}/proxy/metrics\\\\n\\\\n  # Scrape config for Kubelet cAdvisor.\\\\n  #\\\\n  # This is required for Kubernetes 1.7.3 and later, where cAdvisor metrics\\\\n  # (those whose names begin with \\'container_\\') have been removed from the\\\\n  # Kubelet metrics endpoint.  This job scrapes the cAdvisor endpoint to\\\\n  # retrieve those metrics.\\\\n  #\\\\n  # In Kubernetes 1.7.0-1.7.2, these metrics are only exposed on the cAdvisor\\\\n  # HTTP endpoint; use \\\\\\\"replacement: /api/v1/nodes/${1}:4194/proxy/metrics\\\\\\\"\\\\n  # in that case (and ensure cAdvisor\\'s HTTP server hasn\\'t been disabled with\\\\n  # the --cadvisor-port=0 Kubelet flag).\\\\n  #\\\\n  # This job is not necessary and should be removed in Kubernetes 1.6 and\\\\n  # earlier versions, or it will cause the metrics to be scraped twice.\\\\n  - job_name: \\'kubernetes-cadvisor\\'\\\\n\\\\n    # Default to scraping over https. If required, just disable this or change to\\\\n    # `http`.\\\\n    scheme: https\\\\n\\\\n    # This TLS & bearer token file config is used to connect to the actual scrape\\\\n    # endpoints for cluster components. This is separate to discovery auth\\\\n    # configuration because discovery & scraping are two separate concerns in\\\\n    # Prometheus. The discovery auth config is automatic if Prometheus runs inside\\\\n    # the cluster. Otherwise, more config options have to be provided within the\\\\n    # <kubernetes_sd_config\\u003e.\\\\n    tls_config:\\\\n      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\\\\n    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\\\\n\\\\n    kubernetes_sd_configs:\\\\n    - role: node\\\\n\\\\n    relabel_configs:\\\\n    - action: labelmap\\\\n      regex: __meta_kubernetes_node_label_(.+)\\\\n    - target_label: __address__\\\\n      replacement: kubernetes.default.svc:443\\\\n    - source_labels: [__meta_kubernetes_node_name]\\\\n      regex: (.+)\\\\n      target_label: __metrics_path__\\\\n      replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor\\\\n\\\\n  # Scrape config for service endpoints.\\\\n  #\\\\n  # The relabeling allows the actual service scrape endpoint to be configured\\\\n  # via the following annotations:\\\\n  #\\\\n  # * `prometheus.io/scrape`: Only scrape services that have a value of `true`\\\\n  # * `prometheus.io/scheme`: If the metrics endpoint is secured then you will need\\\\n  # to set this to `https` & most likely set the `tls_config` of the scrape config.\\\\n  # * `prometheus.io/path`: If the metrics path is not `/metrics` override this.\\\\n  # * `prometheus.io/port`: If the metrics are exposed on a different port to the\\\\n  # service then set this appropriately.\\\\n  - job_name: \\'kubernetes-service-endpoints\\'\\\\n\\\\n    kubernetes_sd_configs:\\\\n    - role: endpoints\\\\n\\\\n    relabel_configs:\\\\n    - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]\\\\n      action: keep\\\\n      regex: true\\\\n    - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]\\\\n      action: replace\\\\n      target_label: __scheme__\\\\n      regex: (https?)\\\\n    - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]\\\\n      action: replace\\\\n      target_label: __metrics_path__\\\\n      regex: (.+)\\\\n    - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]\\\\n      action: replace\\\\n      target_label: __address__\\\\n      regex: ([^:]+)(?::\\\\d+)?;(\\\\d+)\\\\n      replacement: $1:$2\\\\n    - action: labelmap\\\\n      regex: __meta_kubernetes_service_label_(.+)\\\\n    - source_labels: [__meta_kubernetes_namespace]\\\\n      action: replace\\\\n      target_label: kubernetes_namespace\\\\n    - source_labels: [__meta_kubernetes_service_name]\\\\n      action: replace\\\\n      target_label: kubernetes_name\\\\n\\\\n  # Example scrape config for probing services via the Blackbox Exporter.\\\\n  #\\\\n  # The relabeling allows the actual service scrape endpoint to be configured\\\\n  # via the following annotations:\\\\n  #\\\\n  # * `prometheus.io/probe`: Only probe services that have a value of `true`\\\\n  - job_name: \\'kubernetes-services\\'\\\\n\\\\n    metrics_path: /probe\\\\n    params:\\\\n      module: [http_2xx]\\\\n\\\\n    kubernetes_sd_configs:\\\\n    - role: service\\\\n\\\\n    relabel_configs:\\\\n    - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]\\\\n      action: keep\\\\n      regex: true\\\\n    - source_labels: [__address__]\\\\n      target_label: __param_target\\\\n    - target_label: __address__\\\\n      replacement: blackbox-exporter.example.com:9115\\\\n    - source_labels: [__param_target]\\\\n      target_label: instance\\\\n    - action: labelmap\\\\n      regex: __meta_kubernetes_service_label_(.+)\\\\n    - source_labels: [__meta_kubernetes_namespace]\\\\n      target_label: kubernetes_namespace\\\\n    - source_labels: [__meta_kubernetes_service_name]\\\\n      target_label: kubernetes_name\\\\n\\\\n  # Example scrape config for probing ingresses via the Blackbox Exporter.\\\\n  #\\\\n  # The relabeling allows the actual ingress scrape endpoint to be configured\\\\n  # via the following annotations:\\\\n  #\\\\n  # * `prometheus.io/probe`: Only probe services that have a value of `true`\\\\n  - job_name: \\'kubernetes-ingresses\\'\\\\n\\\\n    metrics_path: /probe\\\\n    params:\\\\n      module: [http_2xx]\\\\n\\\\n    kubernetes_sd_configs:\\\\n      - role: ingress\\\\n\\\\n    relabel_configs:\\\\n      - source_labels: [__meta_kubernetes_ingress_annotation_prometheus_io_probe]\\\\n        action: keep\\\\n        regex: true\\\\n      - source_labels: [__meta_kubernetes_ingress_scheme,__address__,__meta_kubernetes_ingress_path]\\\\n        regex: (.+);(.+);(.+)\\\\n        replacement: ${1}://${2}${3}\\\\n        target_label: __param_target\\\\n      - target_label: __address__\\\\n        replacement: blackbox-exporter.example.com:9115\\\\n      - source_labels: [__param_target]\\\\n        target_label: instance\\\\n      - action: labelmap\\\\n        regex: __meta_kubernetes_ingress_label_(.+)\\\\n      - source_labels: [__meta_kubernetes_namespace]\\\\n        target_label: kubernetes_namespace\\\\n      - source_labels: [__meta_kubernetes_ingress_name]\\\\n        target_label: kubernetes_name\\\\n\\\\n  # Example scrape config for pods\\\\n  #\\\\n  # The relabeling allows the actual pod scrape endpoint to be configured via the\\\\n  # following annotations:\\\\n  #\\\\n  # * `prometheus.io/scrape`: Only scrape pods that have a value of `true`\\\\n  # * `prometheus.io/path`: If the metrics path is not `/metrics` override this.\\\\n  # * `prometheus.io/port`: Scrape the pod on the indicated port instead of the\\\\n  # pod\\'s declared ports (default is a port-free target if none are declared).\\\\n  - job_name: \\'kubernetes-pods\\'\\\\n\\\\n    kubernetes_sd_configs:\\\\n    - role: pod\\\\n\\\\n    relabel_configs:\\\\n    - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]\\\\n      action: keep\\\\n      regex: true\\\\n    - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]\\\\n      action: replace\\\\n      target_label: __metrics_path__\\\\n      regex: (.+)\\\\n    - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]\\\\n      action: replace\\\\n      regex: ([^:]+)(?::\\\\d+)?;(\\\\d+)\\\\n      replacement: $1:$2\\\\n      target_label: __address__\\\\n    - action: labelmap\\\\n      regex: __meta_kubernetes_pod_label_(.+)\\\\n    - source_labels: [__meta_kubernetes_namespace]\\\\n      action: replace\\\\n      target_label: kubernetes_namespace\\\\n    - source_labels: [__meta_kubernetes_pod_name]\\\\n      action: replace\\\\n      target_label: kubernetes_pod_name\"";
	
//	public static final String NAME = "\"test.sh\": \"#!/usr/bin/env bash\\n\\nLOKI_URI=\\\"http://${LOKI_SERVICE}:${LOKI_PORT}\\\"\\n\\nfunction setup() {\\n  apk add -u curl jq\\n  until (curl -s ${LOKI_URI}/api/prom/label/app/values | jq -e '.values[] | select(. == \\\"loki\\\")'); do\\n    sleep 1\\n  done\\n}\\n\\n@test \\\"Has labels\\\" {\\n  curl -s ${LOKI_URI}/api/prom/label | \\\\\\n  jq -e '.values[] | select(. == \\\"app\\\")'\\n}\\n\\n@test \\\"Query log entry\\\" {\\n  curl -sG ${LOKI_URI}/api/prom/query?limit=10 --data-urlencode 'query={app=\\\"loki\\\"}' | \\\\\\n  jq -e '.streams[].entries | length \\u003e= 1'\\n}\\n\\n@test \\\"Push log entry legacy\\\" {\\n  local timestamp=$(date -Iseconds -u | sed 's/UTC/.000000000+00:00/')\\n  local data=$(jq -n --arg timestamp \\\"${timestamp}\\\" '{\\\"streams\\\": [{\\\"labels\\\": \\\"{app=\\\\\\\"loki-test\\\\\\\"}\\\", \\\"entries\\\": [{\\\"ts\\\": $timestamp, \\\"line\\\": \\\"foobar\\\"}]}]}')\\n\\n  curl -s -X POST -H \\\"Content-Type: application/json\\\" ${LOKI_URI}/api/prom/push -d \\\"${data}\\\"\\n\\n  curl -sG ${LOKI_URI}/api/prom/query?limit=1 --data-urlencode 'query={app=\\\"loki-test\\\"}' | \\\\\\n  jq -e '.streams[].entries[].line == \\\"foobar\\\"'\\n}\\n\\n@test \\\"Push log entry\\\" {\\n  local timestamp=$(date +%s000000000)\\n  local data=$(jq -n --arg timestamp \\\"${timestamp}\\\" '{\\\"streams\\\": [{\\\"stream\\\": {\\\"app\\\": \\\"loki-test\\\"}, \\\"values\\\": [[$timestamp, \\\"foobar\\\"]]}]}')\\n\\n  curl -s -X POST -H \\\"Content-Type: application/json\\\" ${LOKI_URI}/loki/api/v1/push -d \\\"${data}\\\"\\n\\n  curl -sG ${LOKI_URI}/api/prom/query?limit=1 --data-urlencode 'query={app=\\\"loki-test\\\"}' | \\\\\\n  jq -e '.streams[].entries[].line == \\\"foobar\\\"'\\n}\\n\"";
	
//	public static final String NAME = "{app=\\\\\\\"loki-test\\\\\\\"}";
	
	public static final String NAME = "\\'evaluation_interval\\'";
	
	/*****************************************************************************************
	 * 
	 * Main
	 * 
	 *****************************************************************************************/

	public static void main(String[] args) throws Exception {
		System.out.println(NAME);
		String replaceAll = NAME.replaceAll("&&", "\\\\u0026\\\\u0026")
				.replaceAll(">", "\\\\u003e")
				.replaceAll("\\'", "\\\\'")
				.replaceAll("\\\\n", "\\\\\\\\\\n")
				.replaceAll("\\\\\"", "\\\\\\\\\\\\\"");
		while (true) {
			if (replaceAll.contains("\\\\\\\\\\")) {
				replaceAll = replaceAll.replace("\\\\\\\\\\", "\\\\\\");
			} else {
				break;
			}
		}
		
		while(true) {
			if (replaceAll.contains("\\'")) {
				replaceAll = replaceAll.replace("\\'", "\\\\'");
			} else {
				break;
			}
		}
		System.out.println(replaceAll);
		
	}
	

	
	
}
